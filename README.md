# 🛡️ Spam News Detection - End-to-End ML Pipeline with DVC

This repository contains a complete Machine Learning (ML) pipeline for detecting spam messages using Natural Language Processing (NLP) techniques. It leverages **DVC** for data and model versioning, **dvclive** for experiment tracking, and is cloud-ready for scalable collaboration via **AWS S3** integration.

---

## 📌 Project Overview

With the exponential rise of spam content in SMS and messaging apps, detecting and filtering spam has become vital. This project builds a robust and reproducible ML workflow from scratch—starting with raw CSV data and ending with a trained, tracked, and evaluated ML model.

---

## 🧠 Problem Statement

Given a collection of SMS messages labeled as "ham" (not spam) or "spam", the goal is to:
- Preprocess text data (tokenize, clean, stem)
- Engineer features using `TF-IDF`
- Train multiple classification models
- Evaluate and track their performance
- Maintain reproducibility and modularity with DVC

---

## 🗃️ Dataset

- 📄 `spam.csv`  
- Source: Public spam detection dataset (e.g., UCI ML repository)
- Format:  
  - `v1`: label (`ham` or `spam`)  
  - `v2`: message text  
  - Unused columns dropped during preprocessing

---

## 🧰 Tech Stack

| Layer             | Tool/Framework            |
|------------------|---------------------------|
| **Language**     | Python 3.x                |
| **ML Framework** | scikit-learn              |
| **NLP**          | NLTK, TF-IDF Vectorizer   |
| **Versioning**   | DVC                       |
| **Experiment Tracking** | dvclive           |
| **Cloud Storage**| AWS S3 (optional setup)   |
| **Logging & Config** | PyYAML, Logging       |
| **Data Handling**| pandas, numpy             |

---

## 🧱 Project Structure

```

sandeshhegde-371-spam-news-detection-complete-ml-pipeline/
├── src/                           # All pipeline stages
│   ├── data\_ingestion.py
│   ├── data\_preprocessing.py
│   ├── feature\_engineering.py
│   ├── model\_training.py
│   └── model\_evaluation.py
├── experiments/                  # Exploratory notebook + dataset
│   ├── mynotebook.ipynb
│   └── spam.csv
├── data/                         # Auto-generated by DVC stages
│   ├── raw/
│   ├── interim/
│   └── processed/
├── models/                       # Trained model (model.pkl)
├── reports/                      # Evaluation metrics
├── dvclive/                      # dvclive experiment logs
│   ├── metrics.json
│   └── plots/metrics/
├── .dvc/                         # DVC internal files
├── dvc.yaml                      # Pipeline stages definition
├── dvc.lock                      # Pipeline snapshot
├── params.yaml                   # Hyperparameters
├── requirements.txt              # Python dependencies
├── projectflow\.txt               # Manual project flow guide
├── README.md
└── LICENSE

````

---

## 🔄 Pipeline Stages with DVC

Each stage is modular and version-controlled via DVC.

| Stage               | Script                     | Output Directory      |
|--------------------|----------------------------|-----------------------|
| **Data Ingestion** | `src/data_ingestion.py`    | `data/raw`            |
| **Preprocessing**  | `src/data_preprocessing.py`| `data/interim`        |
| **Feature Engg.**  | `src/feature_engineering.py`| `data/processed`     |
| **Model Training** | `src/model_training.py`    | `models/model.pkl`    |
| **Evaluation**     | `src/model_evaluation.py`  | `reports/metrics.json`|

---

## 🔧 Parameters (`params.yaml`)

```yaml
data_ingestion:
  test_size: 0.15

feature_engineering:
  max_features: 40

model_building:
  n_estimators: 25
  random_state: 2
````

---

## 📈 Experiment Tracking

We use `dvclive` to log metrics like accuracy, precision, and recall across multiple experiments.

```bash
dvc exp run
dvc exp show
```

Logged metrics are saved in:

* `dvclive/metrics.json`
* `dvclive/plots/metrics/accuracy.tsv`, etc.

---

## 📊 Model Evaluation

Tested multiple models like:

* Logistic Regression, Naive Bayes, Random Forest
* AdaBoost, XGBoost, Extra Trees, etc.

> **Best Accuracy Achieved**: \~97.29%
> **Best Precision**: \~96.55% (Naive Bayes)

---

## ▶️ Getting Started

### 1. Clone the repo

```bash
git clone https://github.com/your-username/spam-detection-ml-pipeline.git
cd spam-detection-ml-pipeline
```

### 2. Create environment

```bash
pip install -r requirements.txt
```

### 3. Initialize DVC

```bash
dvc init
dvc repro
```

---

## 🧪 To Run the Pipeline Manually

```bash
# Run each stage individually
python src/data_ingestion.py
python src/data_preprocessing.py
python src/feature_engineering.py
python src/model_training.py
python src/model_evaluation.py
```

---

## 🌩️ Optional: Connect to AWS S3 (for remote storage)

```bash
dvc remote add -d myremote s3://your-s3-bucket-name
dvc remote modify myremote access_key_id <your-access-key>
dvc remote modify myremote secret_access_key <your-secret-key>
dvc push
```

---

## 🧪 Run Experiments

```bash
# After changing params.yaml or model code
dvc exp run
dvc exp show
```

---

## 📜 License

This project is licensed under the [MIT License](./LICENSE) © 2025 Sandesh Hegde.

---

## 🙌 Acknowledgements

* UCI SMS Spam Dataset
* DVC Team & Community
* scikit-learn, NLTK, and PyYAML contributors

---

## 💬 Contact

Created with 💻 by **[Sandesh Hegde](https://github.com/sandeshhegde-371)**
Reach out via GitHub issues or drop a message!

